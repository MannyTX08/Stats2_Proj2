<<<<<<< HEAD
=======
# The passenger departed from S and had Pclass = 3, lets find an appropriate value
# Replace missing fare value with median fare for class/embarkment
nullFare = full[is.na(full$Fare),] #1044
ggplot(full[full$Pclass == '3' & full$Embarked == 'S', ], aes(x = Fare)) +
geom_density(fill = '#99d6ff', alpha=0.4) +
geom_vline(aes(xintercept=median(Fare, na.rm=T)),colour='red', linetype='dashed', lwd=1) +
scale_x_continuous(breaks = seq(0,70,10), labels=dollar_format()) +
ggtitle("Density of Ticket Fare for Embarked = S and Pclass = 3",
subtitle = paste0("Median Fare: $",
median(full[full$Pclass == '3' & full$Embarked == 'S', ]$Fare, na.rm=T))) +
theme_few()
full$Fare[1044] <- median(full[full$Pclass == '3' & full$Embarked == 'S', ]$Fare, na.rm = TRUE) # $8.05
# Using mice package impute values for Age that are missing
sum(is.na(train$Age)) # 177 missing values
sum(is.na(full$Age))  # 263 missing values in both train and test
# Create Age as a categorical variable
#   Be sure to run this BEFORE imputing with mice and rf
full$AgeBin<-addNA(cut(full$Age, seq(0, 90, by=10)))
#full$AgeBin[10:35]
l<-levels(full$AgeBin)[-(length(levels(full$AgeBin)))]
#l
#    replace <NA> with 'unknown'
levels(full$AgeBin)<-c(l, 'unknown')
full$AgeBin[10:35]
# Create a family = siblings + parents/children
# -Possibly for dimension reducing
full$Family = full$Parch + full$SibSp
# Make variables factors into factors
factor_vars <- c('PassengerId','Pclass','Sex','Embarked','Title', 'AgeBin')
full[factor_vars] <- lapply(full[factor_vars], function(x) as.factor(x))
# Set a random seed
set.seed(129)
# Perform mice imputation, excluding certain less-than-useful variables:
mice_mod <- mice(full[, !names(full) %in% c('PassengerId','Name','Ticket','Cabin','Survived')], method='rf')
# Save the complete output
mice_output <- complete(mice_mod)
# Plot age distributions of raw data against imputed from mice package
par(mfrow=c(1,2))
hist(full$Age, freq=F, main='Age: Original Data', col='lightblue', ylim=c(0,0.04))
hist(mice_output$Age, freq=F, main='Age: MICE Imputation Output', col='lightblue', ylim=c(0,0.04))
# Replace Age variable from the mice model
full$Age <- mice_output$Age
# Show new number of missing Age values is now 0
sum(is.na(full$Age))
# Create DF of independent/dependent variables
nonvars = c("PassengerId","Name","Ticket","Cabin")
full2 = full[,!(names(full) %in% nonvars)]
str(full2)
convert.vars <- c('Pclass','Sex','Embarked','Title', 'AgeBin')
full2[convert.vars] <- lapply(full2[convert.vars], function(x) as.numeric(x))
# Get back to train data set
train1 <- full[!is.na(full$Survived),!(names(full) %in% nonvars)]
test1 <- full[is.na(full$Survived),!(names(full) %in% nonvars)]
train2 <- full2[!is.na(full2$Survived),]
test2 <- full2[is.na(full2$Survived),]
# Structure & Correlation matrix
str(train2)
cor(train2)
#INPUT:  train2     CLEAN DATA STORED IN WORKSPACE, ALL NUMERIC
#INPUT:  test2      CLEAN DATA STORED IN WORKSPACE, ALL NUMERIC
source('KaggelSubmission.R', echo=TRUE)
rm(list=ls())
for(lib in install.lib){
install.packages(lib,dependences=TRUE)
}
# Load necessary packages and ensure they are active
load.lib = c("randomForest","ggplot2","ggthemes","mice","scales","dplyr","Amelia","ROCR", "boot", "bestglm")
install.lib = load.lib[!load.lib %in% installed.packages()]
for(lib in install.lib){
install.packages(lib,dependences=TRUE)
}
suppressMessages(sapply(load.lib,require,character=TRUE))
###### IMPORT DATA / CLEAN DATA / IMPUTE VARIABLES / CREATE NEW VARIABLES
#INPUT: train.csv   RAW DATA FROM KAGGLE
#INPUT: test.csv    RAW DATA FROM KAGGLE
source('BaseVars.R', echo=TRUE)
#OUTPUT: train      RAW DATA LOADED IN WORKSPACE
#OUTPUT: test       RAW DATA LOADED IN WORKSPACE
>>>>>>> f95f5b42a0572e2433f77a8eb9beb00d65f073a1
#OUTPUT: train1     CLEAN DATA STORED IN WORKSPACE
#OUTPUT: test1      CLEAN DATA STORED IN WORKSPACE
#OUTPUT: train2     CLEAN DATA STORED IN WORKSPACE, ALL NUMERIC
#OUTPUT: test2      CLEAN DATA STORED IN WORKSPACE, ALL NUMERIC
install.packages("glmnet")
# Load necessary packages and ensure they are active
load.lib = c("randomForest","ggplot2","ggthemes","mice","scales","dplyr","Amelia","ROCR", "boot", "bestglm", "glmnet")
install.lib = load.lib[!load.lib %in% installed.packages()]
for(lib in install.lib){
install.packages(lib,dependences=TRUE)
}
suppressMessages(sapply(load.lib,require,character=TRUE))
# Load necessary packages and ensure they are active
load.lib = c("randomForest","ggplot2","ggthemes","mice","scales","dplyr","Amelia","ROCR", "boot", "bestglm", "glmnet")
install.lib = load.lib[!load.lib %in% installed.packages()]
for(lib in install.lib){
install.packages(lib,dependences=TRUE)
}
suppressMessages(sapply(load.lib,require,character=TRUE))
setwd("~/Stats@_Proj2/")
getwd()
setwd("~/Stats2_Proj2/")
# Load necessary packages and ensure they are active
load.lib = c("randomForest","ggplot2","ggthemes","mice","scales","dplyr","Amelia","ROCR", "boot", "bestglm")
install.lib = load.lib[!load.lib %in% installed.packages()]
for(lib in install.lib){
install.packages(lib,dependences=TRUE)
}
suppressMessages(sapply(load.lib,require,character=TRUE))
install.packages("bestglm")
# Load necessary packages and ensure they are active
load.lib = c("randomForest","ggplot2","ggthemes","mice","scales","dplyr","Amelia","ROCR", "boot", "bestglm")
install.lib = load.lib[!load.lib %in% installed.packages()]
for(lib in install.lib){
install.packages(lib,dependences=TRUE)
}
suppressMessages(sapply(load.lib,require,character=TRUE))
#INPUT: train.csv   RAW DATA FROM KAGGLE
#INPUT: test.csv    RAW DATA FROM KAGGLE
source('BaseVars.R', echo=TRUE)
X<-train1[, !(names(train1) %in% c("Pclass", "Sex", "Embarked", "Title", "AgeBin", "Survived"))]
y<-train1[, "Survived"]
testglm2<-glmnet(x=X, y=Y, family="binomial")
library(glmnet)
testglm2<-glmnet(x=X, y=Y, family="binomial")
testglm2<-glmnet(x=X, y=y, family="binomial")
testglm2<-glmnet(x=X, y=as.factor(y), family="binomial")
testglm2<-glmnet(x=as.matrix(X), y=as.factor(y), family="binomial")
ls(testglm2)
summary(testglm2)
testglm2$beta
str(train1)
train1$Male = (train1$Sex == "male")*1
train1$Female = (train1$Sex == "female") * 1
train1$Class1 = (train1$Pclass == "1")*1
train1$Class2 = (train1$Pclass == "2")*1
train1$Class3 = (train1$Pclass == "3")*1
train1$PortC = (train1$Embarked == "C")*1
train1$PortQ = (train1$Embarked == "Q")*1
train1$PortS = (train1$Embarked == "S")*1
train1$Child = (train1$AgeBin == "6 or less")*1
train1$Adult= (train1$AgeBin == "(7 - 63]")*1
train1$Senior = (train1$AgeBin == "Over 63")*1
#lapply(levels(train1$Title), function(x) paste("train1", x, sep="$"))
train$Master = (train1$Title == "Master")*1
train1$Miss  = (train1$Title == "Miss")*1
train1$Mr    = (train1$Title == "Mr")*1
train1$Mrs   = (train1$Title == "Mrs")*1
train1$uncommon= (train1$Title == "uncommon")*1
table(	train1$Male, train1$Sex )
table(	train1$Female, train1$Sex )
table(	train1$Class1, train1$Pclass)
table(	train1$Class2, train1$Pclass )
table(	train1$Class3, train1$Pclass 	)
table(	train1$PortC, train1$Embarked 	)
table(	train1$PortQ, train1$Embarked 	)
table(	train1$PortS, train1$Embarked 	)
table(	train1$Child, train1$AgeBin	)
table(	train1$Senior, train1$AgeBin 	)
table(	train1$Adult, train1$AgeBin 	)
table(	train$Master, train1$Title )
table(	train1$Miss, train1$Title 	)
table(	train1$Mr, train1$Title )
table(	train1$Mrs, train1$Title )
table(	train1$uncommon, train1$Title	)
test1$Male = (test1$Sex == "male")*1
test1$Female = (test1$Sex == "female") * 1
test1$Class1 = (test1$Pclass == "1")*1
test1$Class2 = (test1$Pclass == "2")*1
test1$Class3 = (test1$Pclass == "3")*1
test1$PortC = (test1$Embarked == "C")*1
test1$PortQ = (test1$Embarked == "Q")*1
test1$PortS = (test1$Embarked == "S")*1
test1$Child = (test1$AgeBin == "6 or less")*1
test1$Adult= (test1$AgeBin == "(7 - 63]")*1
test1$Senior = (test1$AgeBin == "Over 63")*1
#lapply(levels(test1$Title), function(x) paste("test1", x, sep="$"))
train$Master = (test1$Title == "Master")*1
test1$Miss  = (test1$Title == "Miss")*1
test1$Mr    = (test1$Title == "Mr")*1
test1$Mrs   = (test1$Title == "Mrs")*1
test1$uncommon= (test1$Title == "uncommon")*1
str(train1)
train1$Male = (train1$Sex == "male")*1
train1$Female = (train1$Sex == "female") * 1
train1$Class1 = (train1$Pclass == "1")*1
train1$Class2 = (train1$Pclass == "2")*1
train1$Class3 = (train1$Pclass == "3")*1
train1$PortC = (train1$Embarked == "C")*1
train1$PortQ = (train1$Embarked == "Q")*1
train1$PortS = (train1$Embarked == "S")*1
train1$Child = (train1$AgeBin == "6 or less")*1
train1$Adult= (train1$AgeBin == "(7 - 63]")*1
train1$Senior = (train1$AgeBin == "Over 63")*1
#lapply(levels(train1$Title), function(x) paste("train1", x, sep="$"))
train1$Master = (train1$Title == "Master")*1
train1$Miss  = (train1$Title == "Miss")*1
train1$Mr    = (train1$Title == "Mr")*1
train1$Mrs   = (train1$Title == "Mrs")*1
train1$uncommon= (train1$Title == "uncommon")*1
table(	train1$Male, train1$Sex )
table(	train1$Female, train1$Sex )
table(	train1$Class1, train1$Pclass)
table(	train1$Class2, train1$Pclass )
table(	train1$Class3, train1$Pclass 	)
table(	train1$PortC, train1$Embarked 	)
table(	train1$PortQ, train1$Embarked 	)
table(	train1$PortS, train1$Embarked 	)
table(	train1$Child, train1$AgeBin	)
table(	train1$Senior, train1$AgeBin 	)
table(	train1$Adult, train1$AgeBin 	)
table(	train1$Master, train1$Title )
table(	train1$Miss, train1$Title 	)
table(	train1$Mr, train1$Title )
table(	train1$Mrs, train1$Title )
table(	train1$uncommon, train1$Title	)
test1$Male = (test1$Sex == "male")*1
test1$Female = (test1$Sex == "female") * 1
test1$Class1 = (test1$Pclass == "1")*1
test1$Class2 = (test1$Pclass == "2")*1
test1$Class3 = (test1$Pclass == "3")*1
test1$PortC = (test1$Embarked == "C")*1
test1$PortQ = (test1$Embarked == "Q")*1
test1$PortS = (test1$Embarked == "S")*1
test1$Child = (test1$AgeBin == "6 or less")*1
test1$Adult= (test1$AgeBin == "(7 - 63]")*1
test1$Senior = (test1$AgeBin == "Over 63")*1
#lapply(levels(test1$Title), function(x) paste("test1", x, sep="$"))
train$Master = (test1$Title == "Master")*1
test1$Miss  = (test1$Title == "Miss")*1
test1$Mr    = (test1$Title == "Mr")*1
test1$Mrs   = (test1$Title == "Mrs")*1
test1$uncommon= (test1$Title == "uncommon")*1
str(train1)
train1$Male = (train1$Sex == "male")*1
train1$Female = (train1$Sex == "female") * 1
train1$Class1 = (train1$Pclass == "1")*1
train1$Class2 = (train1$Pclass == "2")*1
train1$Class3 = (train1$Pclass == "3")*1
train1$PortC = (train1$Embarked == "C")*1
train1$PortQ = (train1$Embarked == "Q")*1
train1$PortS = (train1$Embarked == "S")*1
train1$Child = (train1$AgeBin == "6 or less")*1
train1$Adult= (train1$AgeBin == "(7 - 63]")*1
train1$Senior = (train1$AgeBin == "Over 63")*1
#lapply(levels(train1$Title), function(x) paste("train1", x, sep="$"))
train1$Master = (train1$Title == "Master")*1
train1$Miss  = (train1$Title == "Miss")*1
train1$Mr    = (train1$Title == "Mr")*1
train1$Mrs   = (train1$Title == "Mrs")*1
train1$uncommon= (train1$Title == "uncommon")*1
table(	train1$Male, train1$Sex )
table(	train1$Female, train1$Sex )
table(	train1$Class1, train1$Pclass)
table(	train1$Class2, train1$Pclass )
table(	train1$Class3, train1$Pclass 	)
table(	train1$PortC, train1$Embarked 	)
table(	train1$PortQ, train1$Embarked 	)
table(	train1$PortS, train1$Embarked 	)
table(	train1$Child, train1$AgeBin	)
table(	train1$Senior, train1$AgeBin 	)
table(	train1$Adult, train1$AgeBin 	)
table(	train1$Master, train1$Title )
table(	train1$Miss, train1$Title 	)
table(	train1$Mr, train1$Title )
table(	train1$Mrs, train1$Title )
table(	train1$uncommon, train1$Title	)
test1$Male = (test1$Sex == "male")*1
test1$Female = (test1$Sex == "female") * 1
test1$Class1 = (test1$Pclass == "1")*1
test1$Class2 = (test1$Pclass == "2")*1
test1$Class3 = (test1$Pclass == "3")*1
test1$PortC = (test1$Embarked == "C")*1
test1$PortQ = (test1$Embarked == "Q")*1
test1$PortS = (test1$Embarked == "S")*1
test1$Child = (test1$AgeBin == "6 or less")*1
test1$Adult= (test1$AgeBin == "(7 - 63]")*1
test1$Senior = (test1$AgeBin == "Over 63")*1
#lapply(levels(test1$Title), function(x) paste("test1", x, sep="$"))
test1$Master = (test1$Title == "Master")*1
test1$Miss  = (test1$Title == "Miss")*1
test1$Mr    = (test1$Title == "Mr")*1
test1$Mrs   = (test1$Title == "Mrs")*1
test1$uncommon= (test1$Title == "uncommon")*1
Xy<-cbind.data.frame( train1[, !(names(train1) %in% c("Pclass", "Sex", "Embarked", "Title", "AgeBin", "Survived"))],
"Survived"=train1[, "Survived"]  )
#  testglm<-bestglm(Xy, family = binomial(link='logit'), IC="CV")
X<-train1[, !(names(train1) %in% c("Pclass", "Sex", "Embarked", "Title", "AgeBin", "Survived"))]
y<-train1[, "Survived"]
testglm2<-glmnet(x=as.matrix(X), y=as.factor(y), family="binomial")
ls(testglm2)
summary(testglm2)
testglm2$beta
# split the training data into a secondary test (not Kaggle)
set.seed(100) # set seed so that same sample can be reproduced in future
testglm2<-glmnet(x=as.matrix(X), y=as.factor(y), family="binomial")
ls(testglm2)
summary(testglm2)
testglm2$beta
testglm3<-cv.glmnet(x=as.matrix(X), y=as.factor(y), type.measure = "mse")
testglm3<-cv.glmnet(x=as.matrix(X), y, type.measure = "mse")
testglm4<-glmnet(x=as.matrix(X), y=as.factor(y), family="binomial")
ls(testglm4)
summary(testglm4)
testglm4<-glmnet(x=as.matrix(X), y=as.factor(y), family="binomial", lambda=testglm3$lambda)
ls(testglm4)
summary(testglm4)
testglm4$df
coef(testglm4)
coef(testglm4, 20)
coef(testglm4, 50)
# split the training data into a secondary test (not Kaggle)
set.seed(200) # set seed so that same sample can be reproduced in future
coef(testglm3, 50)
testglm3<-cv.glmnet(x=as.matrix(X), y, type.measure = "mse")
testglm4<-glmnet(x=as.matrix(X), y=as.factor(y), family="binomial", lambda=testglm3$lambda)
ls(testglm4)
summary(testglm4)
testglm4$df
coef(testglm4, 50)
coef(testglm4, 15)
coef(testglm4, s=0.1)
coef(testglm4, s=0.05)
coef(testglm4, s="lambda.min")
coef(testglm4, s = "lambda.min")
testglm4$lambda
plot(testglm4)
plot(testglm3)
coef(testglm3, s="lambda.min")
T1<-test1[, !(names(test1) %in% c("Pclass", "Sex", "Embarked", "Title", "AgeBin", "Survived"))]
p3<-predict(testglm3, T1, s="lambda.min")
p3<-predict(testglm3, as.matrix(T1), s="lambda.min")
str(X)
str(T1)
str(p3)
dim(p3)
class(testglm3)
class(testglm4)
#INPUT: train.csv   RAW DATA FROM KAGGLE
#INPUT: test.csv    RAW DATA FROM KAGGLE
source('BaseVars.R', echo=TRUE)
#INPUT: train.csv   RAW DATA FROM KAGGLE
#INPUT: test.csv    RAW DATA FROM KAGGLE
source('BaseVars.R', echo=TRUE)
######################
# Using glmnet and LASSO
# Isolate the binary response "Survived" from the training data
GLMTrain.y <- train1$Survived
GLMTrain.y <- as.factor(as.character(GLMTrain.y))
# create train data set while removing "Survived" from the training data
GLMTrain.x <- train1[,!(colnames(train1) == "Survived")]
# isolate categorical/factors from the continuous features, create dummy variable matrix for all factors
GLMTrain.xfactors <- model.matrix(GLMTrain.y ~ GLMTrain.x$Pclass + GLMTrain.x$Sex + GLMTrain.x$SibSp + GLMTrain.x$Parch + GLMTrain.x$Embarked + GLMTrain.x$Title + GLMTrain.x$AgeBin)[, -1]
str(GLMTrain.xfactors)
dim(GLMTrain.xfactors)
GLMTrain.xfactors[1:25,]
ACkaggle<-cbind.data.frame("PassengerID"=test1$PassengerId, "Survived"=round(p3))
write.csv(ACkaggle, file="~/ACKaggle2.csv", row.names = FALSE)
str(p3)
ACkaggle<-cbind.data.frame("PassengerID"=test$PassengerId, "Survived"=round(p3))
write.csv(ACkaggle, file="~/ACKaggle2.csv", row.names = FALSE)
length(p3)
length(test$PassengerId)
str(ACkaggle)
dim(p3)
ACkaggle<-cbind.data.frame("PassengerID"=test$PassengerId, "Survived"=round(p3))
names(ACkaggle)<-c("PassengerID", "Survived")
write.csv(ACkaggle, file="~/ACKaggle2.csv", row.names = FALSE)
str(ACkaggle)
ACkaggle<-cbind.data.frame("PassengerID"=test$PassengerId, "Survived"=round(p3))
names(ACkaggle)<-c("PassengerID", "Survived")
write.csv(ACkaggle, file="~/ACKaggle2.csv", row.names = FALSE)
coef(testglm3, s="lambda.min")
# Load necessary packages and ensure they are active
load.lib = c("randomForest","ggplot2","ggthemes","mice","scales","dplyr","Amelia","ROCR", "boot", "bestglm")
install.lib = load.lib[!load.lib %in% installed.packages()]
for(lib in install.lib){
install.packages(lib,dependences=TRUE)
}
suppressMessages(sapply(load.lib,require,character=TRUE))
###### IMPORT DATA / CLEAN DATA / IMPUTE VARIABLES / CREATE NEW VARIABLES
#INPUT: train.csv   RAW DATA FROM KAGGLE
#INPUT: test.csv    RAW DATA FROM KAGGLE
source('BaseVars.R', echo=TRUE)
#OUTPUT: train      RAW DATA LOADED IN WORKSPACE
#OUTPUT: test       RAW DATA LOADED IN WORKSPACE
#OUTPUT: train1     CLEAN DATA STORED IN WORKSPACE
#OUTPUT: test1      CLEAN DATA STORED IN WORKSPACE
#OUTPUT: train2     CLEAN DATA STORED IN WORKSPACE, ALL NUMERIC
#OUTPUT: test2      CLEAN DATA STORED IN WORKSPACE, ALL NUMERIC
par(mfrow=c(1,1))
par(xpd=NA)
#par(oma=c(3.7,0,0,0))
#par(mar=c(5, 4, 4, 2) + 0.1)
############################
## FUNCTIONS
############################
# Barplot Percentages
summ.percent.by<-function(vec1, vec2, main="Percents", xname='vec1', yname='vec2'){
par(xpd=NA)
par(mar=c(4.5, 4, 4, 2))
#par(oma=c(4.6, 0, 0, 0))
# vec1=train$Pclass
# vec2=train$Survived
# main="Percents"
t<-table(vec1, vec2, dnn=c(xname, yname))
print(t)
t2<-t/apply(t, 1, sum)
barplot(t(t2), col=c('grey', 'lightblue'), legend.text=c('0=Did not Survive','1=Survived'),
main=main, args.legend = list(x="bottom", horiz=TRUE, inset=c(0, -0.3)))
print(t2)
par(mar=c(5, 4, 4, 2) + 0.1)
#par(mar=c(1, 3, 3, 2) + 0.1)
}
summ.percent.by(train$Pclass, train$Survived, main="Percent Survived by Class",
xname='Passenger Class', yname="Survived")
# Dual Histograms
hist.by<-function(vec1, vec2, main="Percents", ymax=25, breaks=breaks, xname='vec1', yname='vec2'){
par(mfrow=c(2,1))
# vec1=train$Fare
# vec2=train$Survived
# main="Percents"
# xname='vec1'
# yname='vec2'
# ymax=25
vec1_1=vec1[vec2==1]
vec1_2=vec1[vec2==0]
t<-table(vec1, vec2, dnn=c(xname, yname))
xmin=min(vec1)
xmax=max(vec1)
ymax=ymax
breaks2=seq(xmin, xmax, length.out = breaks)
par(mar=c(0.2,5,3,3))
hist(vec1_1 , main=main , xlim=c(xmin,xmax), ylab="Freq. Survived", xlab="", ylim=c(0,ymax) , xaxt="n",
las=1 , col="lightblue", breaks=breaks2)
legend("topright", c('Survived', 'Did Not Survive'), col=c('lightblue','tomato3') , pch = 15)
par(mar=c(5,5,0.2,3))
hist(vec1_2 , main= '', xlim=c(xmin,xmax), ylab="Freq. not Survived", xlab=xname, ylim=c(ymax,0) ,
las=1 , col="tomato3"  , breaks=breaks2)
par(mfrow=c(1,1))
<<<<<<< HEAD
par(mar=c(5, 4, 4, 2) + 0.1)
}
# test
hist.by(train$Fare[train$Fare < 150], train$Survived[train$Fare < 150],
main="Histograms of Fare by Survival", ymax=300, breaks=20,
xname='Fare', yname="Survived")
summary(train1[,"Title"])
summary(test1[,"Title"])
summ.percent.by(train1$Title, train1$Survived, main="Proportion Survived by Title",
xname='Passenger Title', yname="Survived")
AgeBin3<-cut(train1$Age, seq(0, 80, by=10))
#levels(AgeBin3)<-c(rep("6 or less", 2), rep("(7 - 63]", 19), rep("Over 63", 9))
summ.percent.by(AgeBin3,
train1$Survived,
main="Proportion Survived by AgeBin",
xname='Age of Passenger (after imputation)', yname="Survived")
AgeBin3<-cut(train1$Age, seq(0, 80, by=10))
#levels(AgeBin3)<-c(rep("6 or less", 2), rep("(7 - 63]", 19), rep("Over 63", 9))
summ.percent.by(AgeBin3,
train1$Survived,
main="Proportion Survived by Age (10 Year Increments)",
xname='Age of Passenger (after imputation)', yname="Survived")
summary(train1[,"AgeBin"])
summary(test1[,"AgeBin"])
# FareBin<-cut(train$Fare, seq(0, 60, by=2))
# l<-levels(FareBin)[-(length(levels(FareBin)))]
# levels(FareBin)<-c(l, '> $58')
summ.percent.by(train1$AgeBin, train1$Survived, main="Proportion Survived by AgeBin",
xname='Age of Passenger', yname="Survived")
AgeBin3<-cut(train1$Age, seq(0, 90, by=3))
levels(AgeBin3)<-c(rep("6 or less", 2), rep("(7 - 60]", 18), rep("Over 60", 10))
summ.percent.by(AgeBin3,
train1$Survived,
main="Proportion Survived by AgeBin",
xname='Age of Passenger (after imputation)', yname="Survived")
# After imputation
AgeBin3<-cut(train1$Age, seq(0, 90, by=3))
summ.percent.by(AgeBin3,
train1$Survived,
main="Proportion Survived by AgeBin",
xname='Age of Passenger (after imputation)', yname="Survived")
# After imputation
AgeBin3<-cut(train1$Age, seq(0, 90, by=2))
summ.percent.by(AgeBin3,
train1$Survived,
main="Proportion Survived by AgeBin",
xname='Age of Passenger (after imputation)', yname="Survived")
summary(train[,"SibSp"])
summary(test[,"SibSp"])
summary(train[,"SibSp"])
summary(test[,"SibSp"])
#   Dual Histograms
hist.by(train$SibSp, train$Survived,
main="Histograms of Fare by Survival", ymax=400, breaks=10,
xname='Fare', yname="Survived")
hist.by(train$SibSp, train$Survived,
main="Histograms of Fare by Survival", ymax=400, breaks=20,
xname='Fare', yname="Survived")
summary(train[,"SibSp"])
summary(test[,"SibSp"])
#   Dual Histograms
hist.by(train$SibSp, train$Survived,
main="Histograms of Fare by Survival", ymax=400, breaks=8,
xname='Fare', yname="Survived")
summary(train[,"SibSp"])
summary(test[,"SibSp"])
#   Dual Histograms
hist.by(train$SibSp, train$Survived,
main="Histograms of Fare by Survival", ymax=400, breaks=10,
xname='Fare', yname="Survived")
summary(train[,"SibSp"])
summary(test[,"SibSp"])
#   Dual Histograms
hist.by(train$SibSp, train$Survived,
main="Histograms of Siblings/Spouses by Survival", ymax=400, breaks=10,
xname='SibSp', yname="Survived")
summary(train[,"Parch"])
summary(test[,"Parch"])
#   Dual Histograms
hist.by(train$SibSp, train$Survived,
main="Histograms of Parents/Children by Survival", ymax=400, breaks=10,
xname='Parch', yname="Survived")
############################
## FARE
############################
summary(train[,"Parch"])
summary(test[,"Parch"])
#   Dual Histograms
hist.by(train$Parch, train$Survived,
main="Histograms of Parents/Children by Survival", ymax=400, breaks=10,
xname='Parch', yname="Survived")
############################
## PARCH
############################
summary(train[,"Parch"])
summary(test[,"Parch"])
#   Dual Histograms
hist.by(train$Parch, train$Survived,
main="Histograms of Parents/Children by Survival", ymax=450, breaks=10,
xname='Parch', yname="Survived")
############################
## Family
############################
summary(train[,"Family"])
summary(test[,"Family"])
#   Dual Histograms
hist.by(train$Family, train$Survived,
main="Histograms of Family Size by Survival", ymax=450, breaks=10,
xname='Family', yname="Survived")
############################
## FAMILY
############################
summary(train1[,"Family"])
summary(test[,"Family"])
#   Dual Histograms
hist.by(train1$Family, train$Survived,
main="Histograms of Family Size by Survival", ymax=450, breaks=10,
xname='Family', yname="Survived")
############################
## FAMILY
############################
summary(train1[,"Family"])
summary(test1[,"Family"])
#   Dual Histograms
hist.by(train1$Family, train$Survived,
main="Histograms of Family Size by Survival", ymax=450, breaks=11,
xname='Family', yname="Survived")
############################
## FAMILY
############################
summary(train1[,"Family"])
summary(test1[,"Family"])
#   Dual Histograms
hist.by(train1$Family, train$Survived,
main="Histograms of Family Size by Survival", ymax=500, breaks=11,
xname='Family', yname="Survived")
summ.percent.by(train$SibSp, train1$Survived, main="Proportion Survived by Fare",
xname='Ticket Price', yname="Survived")
summ.percent.by(train$Parch, train1$Survived, main="Proportion Survived by Fare",
xname='Ticket Price', yname="Survived")
summ.percent.by(train1$Family, train1$Survived, main="Proportion Survived by Fare",
xname='Ticket Price', yname="Survived")
summ.percent.by(train$Parch, train1$Survived, main="Proportion Survived by Parch",
xname='Parch', yname="Survived")
summ.percent.by(train$SibSp, train1$Survived, main="Proportion Survived by SibSp",
xname='SibSp', yname="Survived")
summ.percent.by(train1$Family, train1$Survived, main="Proportion Survived by Family",
xname='Family', yname="Survived")
summ.percent.by(train$SibSp, train1$Survived, main="Proportion Survived by SibSp",
xname='SibSp', yname="Survived")
summ.percent.by(train$Parch, train1$Survived, main="Proportion Survived by Parch",
xname='Parch', yname="Survived")
=======
plot(glmnetfit)
lambda_lse <- glmnetfit$lambda.1se
coef(glmnetfit, s=lambda_lse)
GLMfittedresults <- predict(glmnetfit, newx=GLMTest.x, type='response')
# prepare the test data in a similar manner for GLMNET usage (create dummy variables, matrix, etc.)
# create test data set while removing "Survived" from the test data
GLMTest.x <- test[,!(colnames(test3) == "Survived")]
# isolate the binary response "Attrition" from the test data
GLMTest.y <- test3$Survived
GLMTest.y <- as.factor(as.character(GLMTest.y))
# isolate categorical/factors from the continuous features, create dummy variable matrix for all factors
GLMTest.xfactors <- model.matrix(GLMTest.y ~ GLMTest.x$Pclass + GLMTest.x$Sex + GLMTest.x$SibSp + GLMTest.x$Parch + GLMTest.x$Embarked + GLMTest.x$Title + GLMTest.x$AgeBin)[, -1]
View(GLMTest.x)
# prepare the test data in a similar manner for GLMNET usage (create dummy variables, matrix, etc.)
# create test data set while removing "Survived" from the test data
GLMTest.x <- test3[,!(colnames(test3) == "Survived")]
# isolate the binary response "Attrition" from the test data
GLMTest.y <- test3$Survived
GLMTest.y <- as.factor(as.character(GLMTest.y))
# isolate categorical/factors from the continuous features, create dummy variable matrix for all factors
GLMTest.xfactors <- model.matrix(GLMTest.y ~ GLMTest.x$Pclass + GLMTest.x$Sex + GLMTest.x$SibSp + GLMTest.x$Parch + GLMTest.x$Embarked + GLMTest.x$Title + GLMTest.x$AgeBin)[, -1]
# remove categorical/factors from GLMTest.x as they will be added back in the form of dummy variable matrix from above
#dropcolsGLM <- c("Pclass", "Sex", "SibSp", "Parch", "Embarked", "Title", "AgeBin") # From Above
GLMTest.x <- GLMTest.x[,!(colnames(GLMTest.x) %in% dropcolsGLM)]
# combine GLMTest.x continuous variables with GLMTest.xfactors dummy variable matrix, then converting whole thing to a matrix for glmnet
GLMTest.x <- as.matrix(data.frame(GLMTest.x, GLMTest.xfactors))
# predict based on the test data, type='response' output probabilities in the form of P(y=1|X)
GLMfittedresults <- predict(glmnetfit, newx=GLMTest.x, type='response')
# if P(y=1|X) > 0.5 then y = 1 otherwise y=0
GLMfittedresults <- ifelse(GLMfittedresults > 0.5, 1, 0)
# calculate the mean of the fitted results that don't equal the observed result - IGNORE NAs
misClasificError <- mean(GLMfittedresults != GLMTest.y, na.rm=TRUE) # this adds up all the instances of misclassification then divides by total (via mean)
# print the output as 100% - error
print(paste('Accuracy',1-misClasificError))
#Create ROC curves
pr <- prediction(fittedresults, test$Survived)
View(test3)
pr <- prediction(fittedresults, test3$Survived)
prf <- performance(pr, measure = "tpr", x.measure = "fpr")
plot(prf)
#Ref line indicating poor performance, 50/50
abline(a=0, b= 1)
# calculate area under curve (AUC)
auc <- performance(pr, measure = "auc")
auc <- auc@y.values[[1]]
# print AUC onto plot
text(x = .40, y = .6,paste("AUC = ", round(auc,3), sep = ""))
plot(prf)
#Ref line indicating poor performance, 50/50
segments(0, 0, 1,1)
plot(prf, lwd=2, colorize=TRUE)
# Ref line indicating poor performance, 50/50
segments(0, 0,1,1)
# print AUC onto plot
text(x = .40, y = .6,paste("AUC = ", round(auc,3), sep = ""))
load.lib = c("randomForest","ggplot2","VIM","ggthemes","mice","scales","dplyr","Amelia","ROCR", "boot", "bestglm")
install.lib = load.lib[!load.lib %in% installed.packages()]
for(lib in install.lib){
install.packages(lib,dependences=TRUE)
}
suppressMessages(sapply(load.lib,require,character=TRUE))
install.packages("vcd")
install.packages("laeken")
load.lib = c("randomForest","ggplot2","VIM","ggthemes","mice","scales","dplyr","Amelia","ROCR", "boot", "bestglm")
install.lib = load.lib[!load.lib %in% installed.packages()]
for(lib in install.lib){
install.packages(lib,dependences=TRUE)
}
suppressMessages(sapply(load.lib,require,character=TRUE))
install.packages("VIM")
load.lib = c("randomForest","ggplot2","VIM","ggthemes","mice","scales","dplyr","Amelia","ROCR", "boot", "bestglm")
install.lib = load.lib[!load.lib %in% installed.packages()]
for(lib in install.lib){
install.packages(lib,dependences=TRUE)
}
suppressMessages(sapply(load.lib,require,character=TRUE))
train <- read.csv('Data/train.csv') # Reading from location after clone
Amelia::missmap(train, main="Missing Values in Train Data", col = c("black","light blue"))
test <- read.csv('Data/test.csv') # Reading from location after clone
Amelia::missmap(test, main="Missing Values in Test Data", col = c("black","light blue"))
# Append test to train for data review and cleaning (result column only valid in train)
full <- bind_rows(train, test)
full_aggr = VIM::aggr(full, col=mdc(1:2), numbers=TRUE, sortVars=TRUE, labels=names(full), cex.axis=.7, gap=3, ylab=c("Proportion of missingness","Missingness Pattern"))
View(full)
full_aggr = VIM::aggr(full[,6:10], col=mdc(1:2), numbers=TRUE, sortVars=TRUE, labels=names(full), cex.axis=.7, gap=3, ylab=c("Proportion of missingness","Missingness Pattern"))
full$Title <- gsub('(.*, )|(\\..*)', '', full$Name)
# Currently 18 levels for Factor title
table(full$Sex, full$Title)
uncommon <- c('Dona', 'Lady', 'the Countess','Capt', 'Col', 'Don',
'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer')
full$Title[full$Title == 'Mlle']  <- 'Miss'
full$Title[full$Title == 'Ms']  <- 'Miss'
full$Title[full$Title == 'Mme']  <- 'Mrs'
full$Title[full$Title %in% uncommon]  <- 'uncommon'
# Reduced to 5 levels for Factor Title
table(full$Sex, full$Title)
# Load necessary packages and ensure they are active
load.lib = c("randomForest","ggplot2","ggthemes","mice","scales","dplyr","Amelia","ROCR", "boot", "bestglm","corrplot")
install.lib = load.lib[!load.lib %in% installed.packages()]
for(lib in install.lib){
install.packages(lib,dependencies=TRUE)
}
suppressMessages(sapply(load.lib,require,character=TRUE))
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot(corMatrix, method="color", col=col(200),
type="upper", order="hclust",
addCoef.col = "black", # Add coefficient of correlation
tl.col="black", tl.srt=45, #Text label color and rotation
# Combine with significance
p.mat = p.mat, sig.level = 0.01, insig = "blank",
# hide correlation coefficient on the principal diagonal
diag=FALSE
)
# Load train and test csv files from working directory
# Using Amelia package visualize where we need imputation
#setwd("~/Stats2_Proj2/")
par(mfrow=c(1,2))
train <- read.csv('Data/train.csv') # Reading from location after clone
Amelia::missmap(train, main="Missing Values in Train Data", col = c("black","light blue"))
test <- read.csv('Data/test.csv') # Reading from location after clone
Amelia::missmap(test, main="Missing Values in Test Data", col = c("black","light blue"))
par(mfrow=c(1,1))
# Append test to train for data review and cleaning (result column only valid in train)
full <- bind_rows(train, test)
# Review if components of name, specifically title add to prediction
full$Title <- gsub('(.*, )|(\\..*)', '', full$Name)
# Currently 18 levels for Factor title
table(full$Sex, full$Title)
uncommon <- c('Dona', 'Lady', 'the Countess','Capt', 'Col', 'Don',
'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer')
# Combine different titles into similar category
# Mlle is french for 'Mademoiselle'
# Mme is French for 'Madame'
# https://en.wikipedia.org/wiki/Mademoiselle_(title)
# https://en.wikipedia.org/wiki/French_honorifics
full$Title[full$Title == 'Mlle']  <- 'Miss'
full$Title[full$Title == 'Ms']  <- 'Miss'
full$Title[full$Title == 'Mme']  <- 'Mrs'
full$Title[full$Title %in% uncommon]  <- 'uncommon'
# Reduced to 5 levels for Factor Title
table(full$Sex, full$Title)
# Handle the null Fare in Test
# The passenger departed from S and had Pclass = 3, lets find an appropriate value
# Replace missing fare value with median fare for class/embarkment
nullFare = full[is.na(full$Fare),] #1044
ggplot(full[full$Pclass == '3' & full$Embarked == 'S', ], aes(x = Fare)) +
geom_density(fill = '#99d6ff', alpha=0.4) +
geom_vline(aes(xintercept=median(Fare, na.rm=T)),colour='red', linetype='dashed', lwd=1) +
scale_x_continuous(breaks = seq(0,70,10), labels=dollar_format()) +
ggtitle("Density of Ticket Fare for Embarked = S and Pclass = 3",
subtitle = paste0("Median Fare: $",
median(full[full$Pclass == '3' & full$Embarked == 'S', ]$Fare, na.rm=T))) +
theme_few()
full$Fare[1044] <- median(full[full$Pclass == '3' & full$Embarked == 'S', ]$Fare, na.rm = TRUE) # $8.05
# Using mice package impute values for Age that are missing
sum(is.na(train$Age)) # 177 missing values
sum(is.na(full$Age))  # 263 missing values in both train and test
# Set a random seed
set.seed(129)
# Perform mice imputation, excluding certain less-than-useful variables:
mice_mod <- mice(full[, !names(full) %in% c('PassengerId','Name','Ticket','Cabin','Survived')], method='rf')
# Save the complete output
mice_output <- complete(mice_mod)
# Plot age distributions of raw data against imputed from mice package
par(mfrow=c(1,2))
hist(full$Age, freq=F, main='Age: Original Data', col='lightblue', ylim=c(0,0.04))
hist(mice_output$Age, freq=F, main='Age: MICE Imputation Output', col='lightblue', ylim=c(0,0.04))
# Replace Age variable from the mice model
full$Age <- mice_output$Age
# Show new number of missing Age values is now 0
sum(is.na(full$Age))
# Create Age as a categorical variable
full$AgeBin <- cut(full$Age, seq(0, 90, by=3))
levels(full$AgeBin) <- c(rep("6 or less", 2), rep("(7 - 63]", 19), rep("Over 63", 9))
#full$AgeBin <- cut(full$Age, seq(0, 80, by=10))
#full$AgeBin[10:35]
# l <- levels(full$AgeBin)[-(length(levels(full$AgeBin)))]
# #l
# #    replace <NA> with 'unknown'
#levels(full$AgeBin)<-c(l, 'unknown')
summary(full$AgeBin)
# Create a family = siblings + parents/children
# -Possibly for dimension reducing
full$Family = full$Parch + full$SibSp
# Make variables factors into factors
factor_vars <- c('PassengerId','Pclass','Sex','Embarked','Title', 'AgeBin')
full[factor_vars] <- lapply(full[factor_vars], function(x) as.factor(x))
# Create DF of independent/dependent variables
nonvars = c("PassengerId","Name","Ticket","Cabin")
full2 = full[,!(names(full) %in% nonvars)]
str(full2)
convert.vars <- c('Pclass','Sex','Embarked','Title', 'AgeBin')
full2[convert.vars] <- lapply(full2[convert.vars], function(x) as.numeric(x))
# Get back to train data set
train1 <- full[!is.na(full$Survived),!(names(full) %in% nonvars)]
test1 <- full[is.na(full$Survived),!(names(full) %in% nonvars)]
train2 <- full2[!is.na(full2$Survived),]
test2 <- full2[is.na(full2$Survived),]
# Structure & Correlation matrix
str(train2)
corMatrix = cor(train2)
corMatrix
write.csv(corMatrix, "CorrelationMatrix.csv")
par(mfrow=c(1,1))
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot(corMatrix, method="color", col=col(200),
type="upper", order="hclust",
addCoef.col = "black", # Add coefficient of correlation
tl.col="black", tl.srt=45, #Text label color and rotation
# Combine with significance
p.mat = p.mat, sig.level = 0.01, insig = "blank",
# hide correlation coefficient on the principal diagonal
diag=FALSE
)
corrplot(corMatrix, method="number")
corrplot(corMatrix, method="number", type = "upper")
corrplot(corMatrix, method="number", type = "upper",
addshade = "all", shade.lwd = 1, shade.col = "white")
corrplot(corMatrix, method="number", type = "upper",
addshade = "all", shade.lwd = 1, shade.col = "gray")
corrplot(corMatrix, method="number", type = "upper",
addshade = "all", shade.lwd = 4, shade.col = "gray")
corrplot(corMatrix, method="color", type = "upper",
addshade = "all", shade.lwd = 1, shade.col = "gray")
corrplot(corMatrix, order = "AOE", type = "upper", tl.pos = "d")
corrplot(corMatrix, add = TRUE, type = "lower", method = "number", order = "AOE",
diag = FALSE, tl.pos = "n", cl.pos = "n")
corrplot(corMatrix, add = TRUE, type = "lower", method = "number", order = "original",
diag = FALSE, tl.pos = "n", cl.pos = "n")
corrplot(corMatrix, add = TRUE, type = "lower", method = "number", order = "original",
diag = TRUE, tl.pos = "n", cl.pos = "n")
corrplot(corMatrix, type = "upper", tl.pos = "d")
corrplot(corMatrix, type = "upper")
corrplot(corMatrix, add = TRUE, type = "lower", method = "number", order = "original",
diag = TRUE, tl.pos = "td") #, cl.pos = "n")
corrplot(corMatrix, add = TRUE, type = "upper", method = "number", order = "original",
diag = TRUE, tl.pos = "td") #, cl.pos = "n")
corrplot(corMatrix, add = TRUE, type = "upper", method = "number", order = "original",
diag = FALSE, tl.pos = "td") #, cl.pos = "n")
corrplot(corMatrix, type = "upper", method = "number", order = "original",
diag = FALSE, tl.pos = "td") #, cl.pos = "n")
corrplot(corMatrix, method="color",
type="upper", order="hclust",
addCoef.col = "black", # Add coefficient of correlation
tl.col="black", tl.srt=45, #Text label color and rotation
# Combine with significance
p.mat = p.mat, sig.level = 0.01, insig = "blank",
# hide correlation coefficient on the principal diagonal
diag=FALSE
)
cor.mtest <- function(mat, ...) {
mat <- as.matrix(mat)
n <- ncol(mat)
p.mat<- matrix(NA, n, n)
diag(p.mat) <- 0
for (i in 1:(n - 1)) {
for (j in (i + 1):n) {
tmp <- cor.test(mat[, i], mat[, j], ...)
p.mat[i, j] <- p.mat[j, i] <- tmp$p.value
}
}
colnames(p.mat) <- rownames(p.mat) <- colnames(mat)
p.mat
}
p.mat <- cor.mtest(train2)
head(p.mat[, 1:5])
corrplot(corMatrix, method="color",
type="upper", order="hclust",
addCoef.col = "black", # Add coefficient of correlation
tl.col="black", tl.srt=45, #Text label color and rotation
p.mat = p.mat, sig.level = 0.01, insig = "blank",
diag=FALSE
)
# Load necessary packages and ensure they are active
load.lib = c("randomForest","ggplot2","ggthemes","mice","scales","dplyr","Amelia","ROCR","glmnet","boot","bestglm","corrplot")
install.lib = load.lib[!load.lib %in% installed.packages()]
for(lib in install.lib){
install.packages(lib,dependencies=TRUE)
}
suppressMessages(sapply(load.lib,require,character=TRUE))
# split the training data into a secondary test (not Kaggel)
set.seed(100) # set seed so that same sample can be reproduced in future
# now selecting 80% of data as sample from total 'n' rows of the data
sample <- sample.int(n=nrow(train2), size=floor(.80*nrow(train2)), replace=FALSE)
# subset the data using the sample integer vector created above
train3 <- train2[sample, ]
test3  <- train2[-sample, ]
# Logistic regression full model
TitanicModelFull = glm(Survived ~ ., data = train3, family = binomial(link='logit'))
summary(TitanicModelFull)
View(train3)
fittedresults2 <- predict(TitanicModelRed, newdata=test3, type='response')
fittedresults <- predict(TitanicModelFull, newdata=test3, type='response')
# count any NAs in the fittedresults
sum(is.na(fittedresults))
# if P(y=1|X) > 0.5 then y = 1 otherwise y=0
fittedresults <- ifelse(fittedresults > 0.5, 1, 0)
>>>>>>> f95f5b42a0572e2433f77a8eb9beb00d65f073a1
