for(lib in install.lib){
install.packages(lib,dependences=TRUE)
}
load.lib = c("kableExtra","ggplot2","ggthemes","mice","scales","dplyr")
install.lib = load.lib[!load.lib %in% installed.packages()]
for(lib in install.lib){
install.packages(lib,dependences=TRUE)
}
sapply(load.lib,require,character=TRUE)
load.lib = c("kableExtra","ggplot2","ggthemes","mice","scales","dplyr")
install.lib = load.lib[!load.lib %in% installed.packages()]
for(lib in install.lib){
install.packages(lib,dependences=TRUE)
}
install.packages("mice")
install.packages("ggthemes")
load.lib = c("kableExtra","ggplot2","ggthemes","mice","scales","dplyr")
install.lib = load.lib[!load.lib %in% installed.packages()]
for(lib in install.lib){
install.packages(lib,dependences=TRUE)
}
sapply(load.lib,require,character=TRUE)
load.lib = c("kableExtra","ggplot2","ggthemes","mice","scales","dplyr")
install.lib = load.lib[!load.lib %in% installed.packages()]
for(lib in install.lib){
install.packages(lib,dependences=TRUE)
}
sapply(load.lib,require,character=TRUE)
wd()
getwd()
# Load train and test csv files from working directory
train <- read.csv("~/Data/train.csv")
# Load train and test csv files from working directory
train <- read.csv('../Data/train.csv')
# Load train and test csv files from working directory
train <- read.csv('./Data/train.csv')
test <- read.csv('./Data/test.csv')
# Append test to train for data review and cleaning
full <- bind_rows(train, test)
warnings()
# Append test to train for data review and cleaning
full <- rbind(train, test)
View(full)
# Review if components of name, specifically title add to prediction
full$Title <- gsub('(.*, )|(\\..*)', '', full$Name)
table(full$Sex, full$Title)
uncommon <- c('Dona', 'Lady', 'the Countess','Capt', 'Col', 'Don',
'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer')
full$Title[full$Title == 'Mlle']  <- 'Miss'
full$Title[full$Title == 'Ms']  <- 'Miss'
full$Title[full$Title == 'Mme']  <- 'Mrs'
full$Title[full$Title %in% uncommon]  <- 'uncommon'
table(full$Sex, full$Title)
ncol(table(full$Sex, full$Title))
missmap(full, main="Missing Values in Raw Data")
??missmap
load.lib = c("kableExtra","ggplot2","ggthemes","mice","scales","dplyr","Amelia")
install.lib = load.lib[!load.lib %in% installed.packages()]
for(lib in install.lib){
install.packages(lib,dependences=TRUE)
}
sapply(load.lib,require,character=TRUE)
Amelia::missmap(full, main="Missing Values in Raw Data")
Amelia::missmap(train, main="Missing Values in Raw Data")
Amelia::missmap(train, main="Missing Values in Raw Data", col = c("red","grey"))
Amelia::missmap(train, main="Missing Values in Raw Data", col = c("red","light blue"))
Amelia::missmap(train, main="Missing Values in Raw Data", col = c("black","light blue"))
Amelia::missmap(test, main="Missing Values in Raw Data", col = c("black","light blue"))
# Using mice package impute values for Age that are missing
sum(is.na(full$Age))
# Using mice package impute values for Age that are missing
sum(is.na(train$Age))
factor_vars <- c('PassengerId','Pclass','Sex','Embarked','Title')
full[factor_vars] <- lapply(full[factor_vars], function(x) as.factor(x))
set.seed(129)
mice_mod <- mice(full[, !names(full) %in% c('PassengerId','Name','Ticket','Cabin','Survived')], method='rf')
install.packages("mice",dependencies = TRUE)
install.packages("mice",dependencies = TRUE)
install.packages("mice", dependencies = TRUE)
mice_mod <- mice(full[, !names(full) %in% c('PassengerId','Name','Ticket','Cabin','Survived')], method='rf')
# Load necessary packages and ensure they are active
load.lib = c("kableExtra","ggplot2","ggthemes","mice","scales","dplyr","Amelia")
install.lib = load.lib[!load.lib %in% installed.packages()]
for(lib in install.lib){
install.packages(lib,dependences=TRUE)
}
sapply(load.lib,require,character=TRUE)
library("randomForest", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
mice_mod <- mice(full[, !names(full) %in% c('PassengerId','Name','Ticket','Cabin','Survived')], method='rf')
View(mice_mod)
# Save the complete output
mice_output <- complete(mice_mod)
par(mfrow=c(1,2))
hist(full$Age, freq=F, main='Age: Original Data', ylim=c(0,0.04))
hist(mice_output$Age, freq=F, main='Age: MICE Imputation Output', ylim=c(0,0.04))
# Plot age distributions
par(mfrow=c(1,2))
hist(full$Age, freq=F, main='Age: Original Data', col='lightblue', ylim=c(0,0.04))
hist(mice_output$Age, freq=F, main='Age: MICE Imputation Output', col='lightblue', ylim=c(0,0.04))
# Replace Age variable from the mice model.
full$Age <- mice_output$Age
# Show new number of missing Age values
sum(is.na(full$Age))
sextest=as.numeric(train$sex)
cor(train)
nonvars = c("PassengerId","Name","Ticket","Cabin")
full = full[,!(names(frain) %in% nonvars)]
str(frain)
nonvars = c("PassengerId","Name","Ticket","Cabin")
full2 = full[,!(names(full) %in% nonvars)]
str(full2)
cor(full2)
full2$Sex = as.numeric(full2$Sex)
cor(full2)
summary(full2$Sex)
convert.vars <- c('Pclass','Sex','Embarked','Title')
full2[convert.vars] <- lapply(full2[convert.vars], function(x) as.numeric(x))
cor(full2)
View(full2)
train2 <- full2[is.na(full2$Survived),]
cor(train2)
View(train2)
train2 <- full2[!is.na(full2$Survived),]
cor(train2)
TitanicLog1 = glm(Survived ~ ., data = trains, family = binomial)
summary(TitanicLog1)
TitanicLog1 = glm(Survived ~ ., data = train2, family = binomial)
summary(TitanicLog1)
test2 <- full2[is.na(full2$Survived),]
TitanicLog1 = glm(Survived ~ ., data = train2, family = binomial(link='logit'))
summary(TitanicLog1)
fittedresults <- predict(TitanicLog1, newdata=test2, type='response')
# count any NAs in the fittedresults
sum(is.na(fittedresults))
# if P(y=1|X) > 0.5 then y = 1 otherwise y=0
fittedresults <- ifelse(fittedresults > 0.5, 1, 0)
# calculate the mean of the fitted results that don't equal the observed result - IGNORE NAs
misClasificError <- mean(fittedresults != test2$Survived, na.rm=TRUE) # this adds up all the instances of misclassification then divides by total (via mean)
# print the output as 100% - error
print(paste('Accuracy',1-misClasificError))
View(train2)
# now selecting 75% of data as sample from total 'n' rows of the data
sample <- sample.int(n=nrow(train2), size=floor(.75*nrow(train2), replace=FALSE))
# now selecting 75% of data as sample from total 'n' rows of the data
sample <- sample.int(n=nrow(train2), size=floor(.75*nrow(train2)), replace=FALSE)
train3 <- train2[sample, ]
test3  <- train2[-sample, ]
TitanicLog1 = glm(Survived ~ ., data = train3, family = binomial(link='logit'))
summary(TitanicLog1)
fittedresults <- predict(TitanicLog1, newdata=test3, type='response')
# predict based on the test data, type='response' output probabilities in the form of P(y=1|X)
fittedresults <- predict(model, newdata=test3, type='response')
# count any NAs in the fittedresults
sum(is.na(fittedresults))
fittedresults <- predict(TitanicLog1, newdata=test3, type='response')
sum(is.na(fittedresults))
fittedresults <- ifelse(fittedresults > 0.5, 1, 0)
misClasificError <- mean(fittedresults != test2$Survived, na.rm=TRUE)
misClasificError <- mean(fittedresults != test3$Survived, na.rm=TRUE)
print(paste('Accuracy',1-misClasificError))
pr <- prediction(fittedresults, test3$Survived)
load.lib = c("randomForest","ggplot2","ggthemes","mice","scales","dplyr","Amelia","ROCR")
install.lib = load.lib[!load.lib %in% installed.packages()]
for(lib in install.lib){
install.packages(lib,dependences=TRUE)
}
sapply(load.lib,require,character=TRUE)
pr <- ROCR::prediction(fittedresults, test3$Survived)
prf <- performance(pr, measure = "tpr", x.measure = "fpr")
plot(prf)
auc <- performance(pr, measure = "auc")
auc <- auc@y.values[[1]]
auc
prf <- ROCR::performance(pr, measure = "tpr", x.measure = "fpr")
# Load necessary packages and ensure they are active
load.lib = c("randomForest","ggplot2","ggthemes","mice","scales","dplyr","Amelia","ROCR")
install.lib = load.lib[!load.lib %in% installed.packages()]
for(lib in install.lib){
install.packages(lib,dependences=TRUE)
}
sapply(load.lib,require,character=TRUE)
supressWarnings(sapply(load.lib,require,character=TRUE))
suppressWarnings(sapply(load.lib,require,character=TRUE))
train <- read.csv('./Data/train.csv')
Amelia::missmap(train, main="Missing Values in Raw Data", col = c("black","light blue"))
test <- read.csv('./Data/test.csv')
Amelia::missmap(test, main="Missing Values in Raw Data", col = c("black","light blue"))
# Append test to train for data review and cleaning (result column only valid in train)
full <- bind_rows(train, test)
# Review if components of name, specifically title add to prediction
full$Title <- gsub('(.*, )|(\\..*)', '', full$Name)
# Currently 18 levels for Factor title
table(full$Sex, full$Title)
uncommon <- c('Dona', 'Lady', 'the Countess','Capt', 'Col', 'Don',
'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer')
full$Title[full$Title == 'Mlle']  <- 'Miss'
full$Title[full$Title == 'Ms']  <- 'Miss'
full$Title[full$Title == 'Mme']  <- 'Mrs'
full$Title[full$Title %in% uncommon]  <- 'uncommon'
# Reduced to 5 levels for Factor Title
table(full$Sex, full$Title)
# Using mice package impute values for Age that are missing
sum(is.na(train$Age)) # 177 missing values
sum(is.na(full$Age))  # 263 missing values in both train and test
# Make variables factors into factors
factor_vars <- c('PassengerId','Pclass','Sex','Embarked','Title')
# Set a random seed
set.seed(129)
# Perform mice imputation, excluding certain less-than-useful variables:
mice_mod <- mice(full[, !names(full) %in% c('PassengerId','Name','Ticket','Cabin','Survived')], method='rf')
# Save the complete output
mice_output <- complete(mice_mod)
# Plot age distributions of raw data against imputed from mice package
par(mfrow=c(1,2))
hist(full$Age, freq=F, main='Age: Original Data', col='lightblue', ylim=c(0,0.04))
hist(mice_output$Age, freq=F, main='Age: MICE Imputation Output', col='lightblue', ylim=c(0,0.04))
# Replace Age variable from the mice model
full$Age <- mice_output$Age
# Show new number of missing Age values is now 0
sum(is.na(full$Age))
# Create DF of independent/dependent variables
nonvars = c("PassengerId","Name","Ticket","Cabin")
full2 = full[,!(names(full) %in% nonvars)]
str(full2)
convert.vars <- c('Pclass','Sex','Embarked','Title')
full2[convert.vars] <- lapply(full2[convert.vars], function(x) as.numeric(x))
# Get back to train data set
train2 <- full2[!is.na(full2$Survived),]
test2 <- full2[is.na(full2$Survived),]
# Correlation matrix
cor(train2)
# now selecting 75% of data as sample from total 'n' rows of the data
sample <- sample.int(n=nrow(train2), size=floor(.75*nrow(train2)), replace=FALSE)
# subset the data using the sample integer vector created above
train3 <- train2[sample, ]
test3  <- train2[-sample, ]
# Logistic regression model
TitanicLog1 = glm(Survived ~ ., data = train3, family = binomial(link='logit'))
summary(TitanicLog1)
View(train2)
train <- read.csv('~/Stats2_Proj2/Data/train.csv')
pwd
getwd()
train <- read.csv('Data/train.csv')
test <- read.csv('Data/test.csv')
Amelia::missmap(train, main="Missing Values in Raw Data", col = c("black","light blue"))
Amelia::missmap(test, main="Missing Values in Raw Data", col = c("black","light blue"))
# Append test to train for data review and cleaning (result column only valid in train)
full <- bind_rows(train, test)
# Review if components of name, specifically title add to prediction
full$Title <- gsub('(.*, )|(\\..*)', '', full$Name)
# Currently 18 levels for Factor title
table(full$Sex, full$Title)
uncommon <- c('Dona', 'Lady', 'the Countess','Capt', 'Col', 'Don',
'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer')
full$Title[full$Title == 'Mlle']  <- 'Miss'
full$Title[full$Title == 'Ms']  <- 'Miss'
full$Title[full$Title == 'Mme']  <- 'Mrs'
full$Title[full$Title %in% uncommon]  <- 'uncommon'
# Reduced to 5 levels for Factor Title
table(full$Sex, full$Title)
sum(is.na(train$Age)) # 177 missing values
sum(is.na(full$Age))  # 263 missing values in both train and test
# Create Age as a categorical variable
# Create Age as a categorical variable
#   Be sure to run this BEFORE imputing with mice and rf
full$AgeBin<-addNA(cut(full$Age, seq(0, 90, by=10)))
#full$AgeBin[10:35]
l<-levels(full$AgeBin)[-(length(levels(full$AgeBin)))]
#l
#    replace <NA> with 'unknown'
levels(full$AgeBin)<-c(l, 'unknown')
full$AgeBin[10:35]
# Create a family = siblings + parents/children
# -Possibly for dimension reducing
full$Family = full$Parch + full$SibSp
# Make variables factors into factors
factor_vars <- c('PassengerId','Pclass','Sex','Embarked','Title', 'AgeBin')
full[factor_vars] <- lapply(full[factor_vars], function(x) as.factor(x))
# Set a random seed
set.seed(129)
# Perform mice imputation, excluding certain less-than-useful variables:
mice_mod <- mice(full[, !names(full) %in% c('PassengerId','Name','Ticket','Cabin','Survived')], method='rf')
# Save the complete output
mice_output <- complete(mice_mod)
# Plot age distributions of raw data against imputed from mice package
par(mfrow=c(1,2))
hist(full$Age, freq=F, main='Age: Original Data', col='lightblue', ylim=c(0,0.04))
hist(mice_output$Age, freq=F, main='Age: MICE Imputation Output', col='lightblue', ylim=c(0,0.04))
# Replace Age variable from the mice model
full$Age <- mice_output$Age
# Show new number of missing Age values is now 0
sum(is.na(full$Age))
# Create DF of independent/dependent variables
nonvars = c("PassengerId","Name","Ticket","Cabin")
full2 = full[,!(names(full) %in% nonvars)]
str(full2)
convert.vars <- c('Pclass','Sex','Embarked','Title', 'AgeBin')
full2[convert.vars] <- lapply(full2[convert.vars], function(x) as.numeric(x))
# Get back to train data set
train1 <- full[!is.na(full$Survived),!(names(full) %in% nonvars)]
test1 <- full[is.na(full$Survived),!(names(full) %in% nonvars)]
train2 <- full2[!is.na(full2$Survived),]
test2 <- full2[is.na(full2$Survived),]
# Structure & Correlation matrix
str(train2)
cor(train2)
